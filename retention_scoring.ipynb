{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from import_function import import_scoring_data, import_data\n",
    "from features_by_customer_type_3 import customer_type_features\n",
    "from care_features_2 import care_features\n",
    "# from features_by_customer_type import customer_type_features\n",
    "conn = pyodbc.connect(dsn='VerticaProd')\n",
    "ct='New'\n",
    "response=['ABANDONED']\n",
    "#  AND CUSTOMER_DEFINITION_ADJ='NEW TO TURBOTAX'\n",
    "care_cont_features, care_bool_features, care_catag_features, care_cont_score_features, care_bool_score_features, care_catag_score_features=care_features(ct)\n",
    "cont_features,bool_features,catag_features,cont_score_features,bool_score_features,catag_score_features=customer_type_features(ct)\n",
    "data = \"SELECT A.AUTH_ID,ABANDONED, AGE_TAXPAYER, AGI,\tAMOUNT_INCOME_TAX_WITHHELD,\tAMOUNT_INCOME_TAX,\tAMOUNT_REFUND,\tAMOUNT_SALARIES_AND_WAGES,\tAMOUNT_STUDENT_LOAN_INTEREST_DEDUCTION,\tAMOUNT_TAX,\tAMOUNT_TOTAL_DEDUCTIONS,\tAMOUNT_TOTAL_PAYMENTS,\tAMOUNT_TOTAL_TAX,\tCOMPLETED_SKU,\tCOST_PER_CUST_LAG7,\tCOST_PER_CUST,\tCUSTOMER_TYPE,\tDMA_AREA,\tFED_FORM_TYPE,\tFILING_STATUS,\tFIRST_COMPLETE_APP_TYPE,\tFIRST_COMPLETE_DEVICE_TYPE,\tFSCHA_FLAG,\tIMPORT_TYPE,\tNEAUTH_DEVICE_TYPE,\tNUM_DEPENDENTS,\tNUM_EXEMPTIONS,\tNUM_W2,\tPRS_SCORE,\tREFUND_TRANSFER_FLAG,\tREJECT_COUNT,\tREQUIRED_TAKE_FLAG,\tSESSIONS_TO_COMPLETE,\tSTART_DEVICE_TYPE,\tSTATE_ATTACH_COUNT,\tSTUDENT_TAXPAYER,\tTOTAL_REVENUE,\tVAUTH_DEVICE_TYPE FROM CTG_ANALYTICS_WS.SM_RETENTION_MODEL A INNER JOIN CTG_ANALYTICS_WS.SM_CUSTOMER_RANDOM_SAMPLE B ON A.CUSTOMER_KEY=B.CUSTOMER_KEY WHERE TAX_YEAR<2016 \"\n",
    "care_data=\"SELECT DISTINCT  A.AUTH_ID,  TAX_YEAR, AXC_CARE,ENTERING_CONTACT_US_EXPERIENCE,TOTAL_AGENT_INTERACTION_SECONDS,CARE_REFERRER,\tFIRST_HS_INTENT,\tFIRST_SEARCH_MANUAL_LOCATION_DETAIL FROM CTG_ANALYTICS_WS.SM_CARE_DATA_MINING A INNER JOIN CTG_ANALYTICS_WS.SM_CUSTOMER_RANDOM_SAMPLE B ON A.AUTH_ID=B.AUTH_ID WHERE A.TAX_YEAR=2015 \"\n",
    "df_no_pca= import_data(data,care_data, cont_features, bool_features, catag_features,care_cont_features, care_bool_features,care_catag_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bin_cont_features import bin_pca\n",
    "j='True'\n",
    "response='ABANDONED'\n",
    "\n",
    "print df_no_pca.dtypes\n",
    "dummy_pca, length_dict = bin_pca(df_no_pca,response, j)\n",
    "scoring_list=list(dummy_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response='ABANDONED'\n",
    "ct='New'\n",
    "from feature_clustering import feature_clustering\n",
    "i='pca'\n",
    "\n",
    "df_no_pca,y, plsca= feature_clustering(dummy_pca,response, i)\n",
    "print list(df_no_pca)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from clustering import obs_clustering\n",
    "clust='False'\n",
    "df=df_no_pca\n",
    "print df\n",
    "df, df_w_labels, df_w_clust=obs_clustering(df,response,clust)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from get_arrays import get_arrays\n",
    "i='False'\n",
    "j='False'\n",
    "dummy_pca=df\n",
    "response = 'ABANDONED'\n",
    "x, y = get_arrays(dummy_pca, response, i, j)\n",
    "print x.shape\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "selector = SelectPercentile(f_classif, percentile=20)\n",
    "selector.fit(x, y)\n",
    "print selector.pvalues_\n",
    "df_pvalues=pd.DataFrame(selector.pvalues_,columns=['p_value'], index=list(x))\n",
    "print df_pvalues\n",
    "sig_features=df_pvalues[df_pvalues['p_value'] <=0.2]\n",
    "sig_features.reset_index(['index'], inplace=True)\n",
    "sig_features.drop(['p_value'], axis=1, inplace=True)\n",
    "print sig_features\n",
    "\n",
    "\n",
    "x=x[sig_features['index'].tolist()]\n",
    "print x.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "train_sizes, train_scores, valid_scores = learning_curve(RandomForestClassifier(criterion='entropy', n_estimators=20, random_state=np.random.RandomState(0)), x, y,train_sizes=[0.001, 0.01, 0.1, 0.5],  scoring='roc_auc', cv=5)\n",
    "print train_sizes\n",
    "for i in train_scores:\n",
    "    print np.mean(i)\n",
    "for K in valid_scores:\n",
    "    print np.mean(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model_algorithm import algorithm\n",
    "response = 'ABANDONED'\n",
    "models, name = algorithm(x, y, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "ct='New'\n",
    "response=['ABANDONED']\n",
    "filename = 'finalized_model.sav'\n",
    "filename2 ='name.sav'\n",
    "filename3 = 'bin_model.sav'\n",
    "filename4 = 'feature_selection.sav'\n",
    "\n",
    "filename5 ='score_model.sav'\n",
    "from care_features_2 import care_features\n",
    "from predicting_code import transform_to_pca, bin_pca_score_set, get_scoring_arrays, score_set_feature_selection, predict,get_scoring_arrays\n",
    "from import_function import import_scoring_data\n",
    "from features_by_customer_type_3 import customer_type_features\n",
    "defection=pd.DataFrame()\n",
    "care_cont_features, care_bool_features, care_catag_features, care_cont_score_features, care_bool_score_features, care_catag_score_features=care_features(ct)\n",
    "cont_features,bool_features,catag_features,cont_score_features,bool_score_features,catag_score_features=customer_type_features(ct)\n",
    "\n",
    "# load the model from disk\n",
    "models = pickle.load(open(filename, 'rb'))\n",
    "name = pickle.load(open(filename2, 'rb'))\n",
    "length_dict = pickle.load(open(filename3, 'rb'))\n",
    "plsca = pickle.load(open(filename4, 'rb'))\n",
    "\n",
    "\n",
    "scoring_data = \"SELECT  A.AUTH_ID, AGE_TAXPAYER,\tAGI,\tAMOUNT_INCOME_TAX_WITHHELD,\tAMOUNT_INCOME_TAX,\tAMOUNT_REFUND,\tAMOUNT_SALARIES_AND_WAGES,\tAMOUNT_STUDENT_LOAN_INTEREST_DEDUCTION,\tAMOUNT_TAX,\tAMOUNT_TOTAL_DEDUCTIONS,\tAMOUNT_TOTAL_PAYMENTS,\tAMOUNT_TOTAL_TAX,\tCASE WHEN COMPLETED_SKU in ('850|Paid Self Employed','900|Paid Home and Business') then '900|Paid Home and Business' else COMPLETED_SKU end as COMPLETED_SKU ,\tCOST_PER_CUST_LAG7,\tCOST_PER_CUST,\tCUSTOMER_TYPE,\tDMA_AREA,\tFED_FORM_TYPE,\tCASE WHEN FILING_STATUS='MarringFilingSeparately' THEN 'MarriedFilingSeparately' ELSE FILING_STATUS END AS FILING_STATUS  ,\tFIRST_COMPLETE_APP_TYPE,\tFIRST_COMPLETE_DEVICE_TYPE,\tFSCHA_FLAG,\tIMPORT_TYPE,\tNEAUTH_DEVICE_TYPE,\tNUM_DEPENDENTS,\tNUM_EXEMPTIONS,\tNUM_W2,\tPRS_SCORE,\tREFUND_TRANSFER_FLAG,\tREJECT_COUNT,\tREQUIRED_TAKE_FLAG,\tSESSIONS_TO_COMPLETE,\tSTART_DEVICE_TYPE,\tSTATE_ATTACH_COUNT,\tSTUDENT_TAXPAYER,\tTOTAL_REVENUE,\tVAUTH_DEVICE_TYPE FROM CTG_ANALYTICS_WS.SM_RETENTION_MODEL A INNER JOIN CTG_ANALYTICS_WS.SM_CUSTOMER_RANDOM_SCORE_SAMPLE B ON A.CUSTOMER_KEY=B.CUSTOMER_KEY WHERE TAX_YEAR=2016\"\n",
    "care_score_data=\"SELECT DISTINCT  A.AUTH_ID, TAX_YEAR, AXC_CARE,ENTERING_CONTACT_US_EXPERIENCE,TOTAL_AGENT_INTERACTION_SECONDS,CARE_REFERRER,\tFIRST_HS_INTENT,\tFIRST_SEARCH_MANUAL_LOCATION_DETAIL FROM CTG_ANALYTICS_WS.SM_CARE_DATA_MINING A INNER JOIN CTG_ANALYTICS_WS.SM_CUSTOMER_RANDOM_SCORE_SAMPLE B ON A.AUTH_ID=B.AUTH_ID WHERE A.TAX_YEAR=2016 \"\n",
    "\n",
    "scoring_df=import_scoring_data(scoring_data,care_score_data, cont_score_features, bool_score_features, catag_score_features, care_cont_score_features, care_bool_score_features, care_catag_score_features)\n",
    "\n",
    "i, j, k=['False','True','pca' ]\n",
    "print scoring_df\n",
    "scoring_df.reset_index(['AUTH_ID'], inplace=True)\n",
    "\n",
    "index=scoring_df['AUTH_ID']\n",
    "print scoring_df.head()\n",
    "\n",
    "# scoring_df.drop(['AUTH_ID'], axis=1, inplace=True)\n",
    "# new_list2=list(set(list(df_no_pca)) & set(list(scoring_df)))\n",
    "# df_scoring=df_no_pca[new_list2]\n",
    "# scoring_df.reset_index(['CUSTOMER_KEY'], inplace=True)\n",
    "\n",
    "# scoring_df.drop(['CUSTOMER_KEY'], axis=1, inplace=True)\n",
    "# x=scoring_df[scoring_list]\n",
    "# df_trans_pca = transform_to_pca(scoring_df, fitted_pca, i)\n",
    "# print df_trans_pca\n",
    "print length_dict\n",
    "scoring_df_trans = bin_pca_score_set(scoring_df, length_dict, j)\n",
    "\n",
    "print scoring_df_trans.shape, x.shape\n",
    "a=list(x)\n",
    "b=list(scoring_df_trans)\n",
    "final=list(set(b).difference(a))\n",
    "scoring_df_trans.drop(final, axis=1, inplace=True)\n",
    "print scoring_df_trans.shape\n",
    "x.drop(list(scoring_df_trans), axis=1, inplace=True)\n",
    "print x.shape\n",
    "c=list(x)\n",
    "\n",
    "m=scoring_df_trans.shape[0]     \n",
    "n= x.shape[1]\n",
    "print  scoring_df_trans.shape, x.shape\n",
    "\n",
    "zeros_df=pd.DataFrame(np.zeros((m, n)), columns=c).astype('bool')\n",
    "\n",
    "\n",
    "\n",
    "# scoring_df_trans.reset_index(['CUSTOMER_KEY'], inplace=True)\n",
    "print scoring_df_trans\n",
    "\n",
    "final_scoring_df=pd.concat([zeros_df,scoring_df_trans,index ], axis=1)\n",
    "final_scoring_df.set_index('AUTH_ID', inplace=True)\n",
    "print final_scoring_df.shape\n",
    "\n",
    "scoring_df_trans=final_scoring_df\n",
    "print scoring_df_trans.shape\n",
    "x_score, index=score_set_feature_selection(scoring_df_trans,plsca, k)\n",
    "\n",
    "# x_score.set_index('CUSTOMER_KEY', inplace=True)\n",
    "print list(x_score)\n",
    "x_score.drop(['AUTH_ID'], axis=1, inplace=True)\n",
    "df_p=predict(models,name,x_score, index)\n",
    "defection=pd.concat([df_p, defection], axis=1)\n",
    "print defection.head()\n",
    "defection.to_csv(path_or_buf='defection_model_1.txt', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_intersection import scoring_data_intersection\n",
    "y_df=df_no_pca[response]\n",
    "print scoring_df.head()\n",
    "\n",
    "data, _ = scoring_data_intersection(df_no_pca, scoring_df)\n",
    "print data.shape\n",
    "print scoring_df.head()\n",
    "df_pca=pd.concat([y_df, data], axis=1)\n",
    "# df_pca.reset_index(['CUSTOMER_KEY'], inplace=True)\n",
    "print df_pca.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
